{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Smote_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['person_age', 'person_income', 'person_home_ownership', 'loan_intent',\n",
       "       'loan_grade', 'loan_amnt', 'loan_int_rate', 'loan_percent_income',\n",
       "       'loan_status'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>35000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6000</td>\n",
       "      <td>11.49</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "      <td>56000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4000</td>\n",
       "      <td>13.35</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>28800</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6000</td>\n",
       "      <td>8.90</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>70000</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12000</td>\n",
       "      <td>11.11</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>60000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6000</td>\n",
       "      <td>6.92</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age  person_income  person_home_ownership  loan_intent  loan_grade  \\\n",
       "0          37          35000                      0            0           0   \n",
       "1          22          56000                      1            1           1   \n",
       "2          29          28800                      1            2           2   \n",
       "3          30          70000                      0            3           0   \n",
       "4          22          60000                      0            1           2   \n",
       "\n",
       "   loan_amnt  loan_int_rate  loan_percent_income  loan_status  \n",
       "0       6000          11.49                 0.17            0  \n",
       "1       4000          13.35                 0.07            0  \n",
       "2       6000           8.90                 0.21            0  \n",
       "3      12000          11.11                 0.17            0  \n",
       "4       6000           6.92                 0.10            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df[['person_age', 'person_income', 'person_home_ownership',\n",
    "         'loan_intent', 'loan_grade', 'loan_amnt',\n",
    "         'loan_int_rate', 'loan_percent_income']]\n",
    "y = df['loan_status'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_reshaped = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\AI_Projek\\Compettion_Load_Predict\\bakso2\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(65, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(32, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8824 - loss: 0.2770 - val_accuracy: 0.8821 - val_loss: 0.2707\n",
      "Epoch 2/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8867 - loss: 0.2663 - val_accuracy: 0.8832 - val_loss: 0.2700\n",
      "Epoch 3/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8842 - loss: 0.2718 - val_accuracy: 0.8840 - val_loss: 0.2696\n",
      "Epoch 4/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8841 - loss: 0.2718 - val_accuracy: 0.8833 - val_loss: 0.2704\n",
      "Epoch 5/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8849 - loss: 0.2711 - val_accuracy: 0.8831 - val_loss: 0.2704\n",
      "Epoch 6/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8859 - loss: 0.2705 - val_accuracy: 0.8826 - val_loss: 0.2700\n",
      "Epoch 7/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8843 - loss: 0.2705 - val_accuracy: 0.8824 - val_loss: 0.2694\n",
      "Epoch 8/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8871 - loss: 0.2662 - val_accuracy: 0.8845 - val_loss: 0.2685\n",
      "Epoch 9/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8855 - loss: 0.2704 - val_accuracy: 0.8837 - val_loss: 0.2686\n",
      "Epoch 10/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8829 - loss: 0.2737 - val_accuracy: 0.8849 - val_loss: 0.2680\n",
      "Epoch 11/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8858 - loss: 0.2704 - val_accuracy: 0.8833 - val_loss: 0.2685\n",
      "Epoch 12/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8845 - loss: 0.2705 - val_accuracy: 0.8849 - val_loss: 0.2677\n",
      "Epoch 13/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8848 - loss: 0.2701 - val_accuracy: 0.8853 - val_loss: 0.2677\n",
      "Epoch 14/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8873 - loss: 0.2672 - val_accuracy: 0.8853 - val_loss: 0.2676\n",
      "Epoch 15/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8845 - loss: 0.2693 - val_accuracy: 0.8855 - val_loss: 0.2671\n",
      "Epoch 16/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8832 - loss: 0.2710 - val_accuracy: 0.8846 - val_loss: 0.2676\n",
      "Epoch 17/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8853 - loss: 0.2692 - val_accuracy: 0.8843 - val_loss: 0.2677\n",
      "Epoch 18/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8853 - loss: 0.2702 - val_accuracy: 0.8846 - val_loss: 0.2678\n",
      "Epoch 19/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8853 - loss: 0.2688 - val_accuracy: 0.8844 - val_loss: 0.2682\n",
      "Epoch 20/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8854 - loss: 0.2699 - val_accuracy: 0.8847 - val_loss: 0.2672\n",
      "Epoch 21/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8875 - loss: 0.2677 - val_accuracy: 0.8845 - val_loss: 0.2676\n",
      "Epoch 22/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8848 - loss: 0.2672 - val_accuracy: 0.8857 - val_loss: 0.2665\n",
      "Epoch 23/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8870 - loss: 0.2673 - val_accuracy: 0.8845 - val_loss: 0.2666\n",
      "Epoch 24/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8857 - loss: 0.2680 - val_accuracy: 0.8845 - val_loss: 0.2668\n",
      "Epoch 25/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8877 - loss: 0.2662 - val_accuracy: 0.8857 - val_loss: 0.2673\n",
      "Epoch 26/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8868 - loss: 0.2685 - val_accuracy: 0.8858 - val_loss: 0.2665\n",
      "Epoch 27/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8869 - loss: 0.2658 - val_accuracy: 0.8862 - val_loss: 0.2660\n",
      "Epoch 28/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8871 - loss: 0.2673 - val_accuracy: 0.8865 - val_loss: 0.2653\n",
      "Epoch 29/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.2676 - val_accuracy: 0.8868 - val_loss: 0.2656\n",
      "Epoch 30/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8863 - loss: 0.2685 - val_accuracy: 0.8873 - val_loss: 0.2655\n",
      "Epoch 31/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8872 - loss: 0.2660 - val_accuracy: 0.8866 - val_loss: 0.2661\n",
      "Epoch 32/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8874 - loss: 0.2695 - val_accuracy: 0.8871 - val_loss: 0.2654\n",
      "Epoch 33/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8850 - loss: 0.2682 - val_accuracy: 0.8862 - val_loss: 0.2647\n",
      "Epoch 34/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8884 - loss: 0.2645 - val_accuracy: 0.8864 - val_loss: 0.2656\n",
      "Epoch 35/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.2648 - val_accuracy: 0.8867 - val_loss: 0.2649\n",
      "Epoch 36/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8870 - loss: 0.2664 - val_accuracy: 0.8855 - val_loss: 0.2650\n",
      "Epoch 37/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8858 - loss: 0.2675 - val_accuracy: 0.8865 - val_loss: 0.2660\n",
      "Epoch 38/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8866 - loss: 0.2666 - val_accuracy: 0.8870 - val_loss: 0.2656\n",
      "Epoch 39/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8886 - loss: 0.2626 - val_accuracy: 0.8871 - val_loss: 0.2646\n",
      "Epoch 40/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8864 - loss: 0.2672 - val_accuracy: 0.8860 - val_loss: 0.2653\n",
      "Epoch 41/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8863 - loss: 0.2694 - val_accuracy: 0.8874 - val_loss: 0.2645\n",
      "Epoch 42/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8853 - loss: 0.2666 - val_accuracy: 0.8876 - val_loss: 0.2655\n",
      "Epoch 43/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8908 - loss: 0.2641 - val_accuracy: 0.8882 - val_loss: 0.2642\n",
      "Epoch 44/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8880 - loss: 0.2642 - val_accuracy: 0.8873 - val_loss: 0.2641\n",
      "Epoch 45/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8905 - loss: 0.2588 - val_accuracy: 0.8863 - val_loss: 0.2652\n",
      "Epoch 46/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8904 - loss: 0.2618 - val_accuracy: 0.8867 - val_loss: 0.2651\n",
      "Epoch 47/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8877 - loss: 0.2640 - val_accuracy: 0.8865 - val_loss: 0.2644\n",
      "Epoch 48/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8877 - loss: 0.2642 - val_accuracy: 0.8880 - val_loss: 0.2638\n",
      "Epoch 49/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8871 - loss: 0.2658 - val_accuracy: 0.8870 - val_loss: 0.2645\n",
      "Epoch 50/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8878 - loss: 0.2648 - val_accuracy: 0.8866 - val_loss: 0.2658\n",
      "Epoch 51/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8902 - loss: 0.2606 - val_accuracy: 0.8863 - val_loss: 0.2639\n",
      "Epoch 52/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8859 - loss: 0.2662 - val_accuracy: 0.8865 - val_loss: 0.2638\n",
      "Epoch 53/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8899 - loss: 0.2623 - val_accuracy: 0.8876 - val_loss: 0.2633\n",
      "Epoch 54/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7ms/step - accuracy: 0.8884 - loss: 0.2631 - val_accuracy: 0.8875 - val_loss: 0.2646\n",
      "Epoch 55/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8875 - loss: 0.2693 - val_accuracy: 0.8877 - val_loss: 0.2638\n",
      "Epoch 56/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8884 - loss: 0.2630 - val_accuracy: 0.8882 - val_loss: 0.2629\n",
      "Epoch 57/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8895 - loss: 0.2618 - val_accuracy: 0.8877 - val_loss: 0.2632\n",
      "Epoch 58/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8907 - loss: 0.2613 - val_accuracy: 0.8877 - val_loss: 0.2633\n",
      "Epoch 59/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8890 - loss: 0.2627 - val_accuracy: 0.8875 - val_loss: 0.2636\n",
      "Epoch 60/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8861 - loss: 0.2651 - val_accuracy: 0.8865 - val_loss: 0.2639\n",
      "Epoch 61/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8898 - loss: 0.2639 - val_accuracy: 0.8885 - val_loss: 0.2631\n",
      "Epoch 62/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8898 - loss: 0.2605 - val_accuracy: 0.8877 - val_loss: 0.2630\n",
      "Epoch 63/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8882 - loss: 0.2648 - val_accuracy: 0.8881 - val_loss: 0.2628\n",
      "Epoch 64/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8913 - loss: 0.2614 - val_accuracy: 0.8877 - val_loss: 0.2635\n",
      "Epoch 65/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8889 - loss: 0.2622 - val_accuracy: 0.8879 - val_loss: 0.2636\n",
      "Epoch 66/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8893 - loss: 0.2634 - val_accuracy: 0.8881 - val_loss: 0.2628\n",
      "Epoch 67/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.8894 - loss: 0.2591 - val_accuracy: 0.8874 - val_loss: 0.2633\n",
      "Epoch 68/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8914 - loss: 0.2613 - val_accuracy: 0.8882 - val_loss: 0.2628\n",
      "Epoch 69/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8896 - loss: 0.2621 - val_accuracy: 0.8884 - val_loss: 0.2637\n",
      "Epoch 70/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8918 - loss: 0.2577 - val_accuracy: 0.8877 - val_loss: 0.2636\n",
      "Epoch 71/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8903 - loss: 0.2595 - val_accuracy: 0.8883 - val_loss: 0.2628\n",
      "Epoch 72/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.8896 - loss: 0.2617 - val_accuracy: 0.8878 - val_loss: 0.2638\n",
      "Epoch 73/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8897 - loss: 0.2590 - val_accuracy: 0.8875 - val_loss: 0.2622\n",
      "Epoch 74/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8891 - loss: 0.2625 - val_accuracy: 0.8880 - val_loss: 0.2627\n",
      "Epoch 75/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.8895 - loss: 0.2626 - val_accuracy: 0.8897 - val_loss: 0.2624\n",
      "Epoch 76/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8893 - loss: 0.2596 - val_accuracy: 0.8891 - val_loss: 0.2617\n",
      "Epoch 77/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8896 - loss: 0.2591 - val_accuracy: 0.8890 - val_loss: 0.2628\n",
      "Epoch 78/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8886 - loss: 0.2613 - val_accuracy: 0.8889 - val_loss: 0.2622\n",
      "Epoch 79/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8904 - loss: 0.2599 - val_accuracy: 0.8884 - val_loss: 0.2627\n",
      "Epoch 80/80\n",
      "\u001b[1m881/881\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8902 - loss: 0.2595 - val_accuracy: 0.8892 - val_loss: 0.2626\n",
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8897 - loss: 0.2616\n",
      "Test Loss: 0.2629, Test Accuracy: 0.8880\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=80, batch_size=64, validation_split=0.2)\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m944/944\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.92      0.89     15172\n",
      "           1       0.92      0.85      0.88     15005\n",
      "\n",
      "    accuracy                           0.89     30177\n",
      "   macro avg       0.89      0.89      0.89     30177\n",
      "weighted avg       0.89      0.89      0.89     30177\n",
      "\n",
      "Confusion Matrix:\n",
      "[[14011  1161]\n",
      " [ 2218 12787]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Menggunakan threshold 0.5 untuk binarize hasil prediksi\n",
    "predictions_binary = (predictions > 0.5).astype(int)\n",
    "\n",
    "# Menghitung classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, predictions_binary))\n",
    "\n",
    "# Menghitung confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, predictions_binary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft['person_home_ownership'] = dft['person_home_ownership'].map({'RENT' : 0, 'OWN': 1, 'MORTGAGE' : 2, 'OTHER' : 3})\n",
    "dft['loan_intent'] = dft['loan_intent'].map({'EDUCATION' : 0, 'MEDICAL' : 1, 'PERSONAL' : 2, 'VENTURE' : 3, 'DEBTCONSOLIDATION' : 4, 'HOMEIMPROVEMENT' : 5})\n",
    "dft['loan_grade'] = dft['loan_grade'].map({'B' : 0, 'C' : 1, 'A' : 2, 'D' : 3,'E' : 4, 'F' : 5, 'G' : 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rl = dft[['person_age', 'person_income', 'person_home_ownership',\n",
    "                'loan_intent', 'loan_grade', 'loan_amnt',\n",
    "                'loan_int_rate', 'loan_percent_income']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_rl = scaler.fit_transform(X_rl)\n",
    "X_reshapedrl = X_scaled_rl.reshape((X_scaled_rl.shape[0], 1, X_scaled_rl.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1222/1222\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step  \n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_reshapedrl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_1d = predictions.flatten() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    'id': dft['id'],\n",
    "    'loan_status': predictions_1d\n",
    "})\n",
    "\n",
    "# Menyimpan hasil ke CSV\n",
    "results.to_csv('Zoltrak6.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bakso2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
